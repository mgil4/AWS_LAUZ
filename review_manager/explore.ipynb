{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../filtered_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_sentence_embedding(sentence, model, tokenizer):\n",
    "    # Tokenize input sentence\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "    # Get the transformer model output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "\n",
    "    # Extract the output embeddings (CLS token)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Example sentence\n",
    "example_sentence = \"This mobile phone was very good\"\n",
    "\n",
    "# Get sentence embedding\n",
    "sentence_embedding = get_sentence_embedding(example_sentence, model, tokenizer)\n",
    "\n",
    "# Convert to numpy array for easier handling\n",
    "sentence_embedding_np = sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df[\"Product Name\"].value_counts().reset_index()\n",
    "subset = df[df[\"Product Name\"] == counts.iloc[70][\"Product Name\"]]\n",
    "subset = df[df[\"Product Name\"] == \"4 Inch Touch Screen Cell Phone Unlocked, Android Unlocked Gsm Smartphones Dual Camera Dual Sim Dual Standby No Contract (Blue)\"]\n",
    "subset[\"embedding\"] = subset[\"Reviews\"].apply(get_sentence_embedding, args = (model, tokenizer))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=3)\n",
    "embed = np.vstack(subset[\"embedding\"].to_numpy())\n",
    "project = pca.fit_transform(embed)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(embed)\n",
    "subset[\"cluster\"] = clusters\n",
    "subset[\"x\"] = project[:,0]\n",
    "subset[\"y\"] = project[:,1]\n",
    "subset[\"z\"] = project[:,2]\n",
    "#subset[[\"Product Name\", \"x\", \"y\", \"z\", \"cluster\", \"Rating\"]].to_csv(\"../projection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 7))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "ax.scatter3D(project[:,0], project[:,1], project[:,2], c=clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    processed_docs = []\n",
    "    words = [ps.stem(word.lower()) for word in word_tokenize(doc) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return words\n",
    "\n",
    "def calculate_term_frequency(documents):\n",
    "    term_frequency = Counter()\n",
    "    for doc in documents:\n",
    "        term_frequency.update(doc)\n",
    "    return term_frequency\n",
    "\n",
    "subset[\"preprocessed\"] = subset[\"Reviews\"].apply(preprocess)\n",
    "tf_group = [calculate_term_frequency(subset[\"preprocessed\"][subset[\"cluster\"] == i]) for i in range(3)]\n",
    "terms_group_more = [{term: tf_group[i][term] for term in tf_group[i] if tf_group[i][term] > tf_group[(i+1)%3][term] \n",
    "                        and tf_group[i][term] > tf_group[(i+2)%3][term]} for i in range(3)]\n",
    "terms_group_more = [sorted(cnt.items(), key=lambda x: x[1], reverse=True) for cnt in terms_group_more]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forbidden = ['phone', 'device']  # Lista de palabras prohibidas\n",
    "num_words_per_cluster = 5  # Número de palabras por clúster\n",
    "\n",
    "rating_words = [{} for _ in range(3)]\n",
    "\n",
    "for i in range(3):\n",
    "    subset_cluster = subset[subset[\"cluster\"] == i].copy()  # Crear una copia para evitar advertencias\n",
    "\n",
    "    rating_words[i]['total'] = round(subset_cluster[\"Rating\"].mean(), 2)\n",
    "\n",
    "    # Filtrar palabras prohibidas\n",
    "    cluster_words = [word for word in terms_group_more[i] if word[0] not in forbidden][0:num_words_per_cluster]\n",
    "\n",
    "    # Asegúrate de que \"preprocessed\" esté presente en tu DataFrame\n",
    "    if \"preprocessed\" in subset_cluster.columns:\n",
    "        for word in cluster_words:\n",
    "            reviews = subset_cluster[subset_cluster[\"preprocessed\"].apply(lambda x: any(word[0] in s for s in x))]\n",
    "            rating_words[i][word[0]] = round(reviews[\"Rating\"].mean(), 2)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(rating_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=subset, x='Rating', hue='cluster', multiple=\"stack\", bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXEMPLE\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "labels = [str(rating_words[c]).replace(',', '<br>') for c in clusters]\n",
    "# Create a 3D scatter plot with hover text\n",
    "fig = px.scatter_3d(x=project[:,0], y=project[:,1], z=project[:,2], hover_name=labels, color=clusters)\n",
    "\n",
    "# Set layout options for better readability\n",
    "fig.update_layout(\n",
    "    title=\"Interactive 3D Scatter Plot with Hover Text\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"X-axis\",\n",
    "        yaxis_title=\"Y-axis\",\n",
    "        zaxis_title=\"Z-axis\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
