{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"filtered_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_sentence_embedding(sentence, model, tokenizer):\n",
    "    # Tokenize input sentence\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "    # Get the transformer model output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "\n",
    "    # Extract the output embeddings (CLS token)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Example sentence\n",
    "example_sentence = \"This mobile phone was very good\"\n",
    "\n",
    "# Get sentence embedding\n",
    "sentence_embedding = get_sentence_embedding(example_sentence, model, tokenizer)\n",
    "\n",
    "# Convert to numpy array for easier handling\n",
    "sentence_embedding_np = sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df[\"Product Name\"].value_counts().reset_index()\n",
    "subset = df[df[\"Product Name\"] == counts.iloc[100][\"Product Name\"]]\n",
    "subset[\"embedding\"] = subset[\"Reviews\"].apply(get_sentence_embedding, args = (model, tokenizer))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=3)\n",
    "embed = np.vstack(subset[\"embedding\"].to_numpy())\n",
    "project = pca.fit_transform(embed)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(embed)\n",
    "subset[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 7))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "ax.scatter3D(project[:,0], project[:,1], project[:,2], c=clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=subset, x='Rating', hue='cluster', multiple=\"stack\", bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    processed_docs = []\n",
    "    words = [ps.stem(word.lower()) for word in word_tokenize(doc) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return words\n",
    "\n",
    "def calculate_term_frequency(documents):\n",
    "    term_frequency = Counter()\n",
    "    for doc in documents:\n",
    "        term_frequency.update(doc)\n",
    "    return term_frequency\n",
    "\n",
    "subset[\"preprocessed\"] = subset[\"Reviews\"].apply(preprocess)\n",
    "tf_group = [calculate_term_frequency(subset[\"preprocessed\"][subset[\"cluster\"] == i]) for i in range(3)]\n",
    "terms_group_more = [{term: tf_group[i][term] for term in tf_group[i] if tf_group[i][term] > tf_group[(i+1)%3][term] \n",
    "                        and tf_group[i][term] > tf_group[(i+2)%3][term]} for i in range(3)]\n",
    "terms_group_more = [sorted(cnt.items(), key=lambda x: x[1], reverse=True) for cnt in terms_group_more]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_group_more[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Generate some example data\n",
    "data = {\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [2, 3, 5, 4, 1],\n",
    "    'z': [3, 1, 2, 4, 5],\n",
    "    'labels': terms_group_more[0][0:5]\n",
    "}\n",
    "\n",
    "# Create a 3D scatter plot with hover text\n",
    "fig = px.scatter_3d(data, x='x', y='y', z='z', hover_name='labels')\n",
    "\n",
    "# Set layout options for better readability\n",
    "fig.update_layout(\n",
    "    title=\"Interactive 3D Scatter Plot with Hover Text\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"X-axis\",\n",
    "        yaxis_title=\"Y-axis\",\n",
    "        zaxis_title=\"Z-axis\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
